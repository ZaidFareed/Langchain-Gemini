{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Install Langchain"
      ],
      "metadata": {
        "id": "YU9bPqeyNnrQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "fIYfKr5aFF5F",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "deb03a21-1c7e-4c8d-fedf-45da72d483f6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.11/dist-packages (0.3.16)\n",
            "Collecting langchain\n",
            "  Downloading langchain-0.3.17-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting langchain-community\n",
            "  Downloading langchain_community-0.3.16-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting langchain-google-genai\n",
            "  Downloading langchain_google_genai-2.0.9-py3-none-any.whl.metadata (3.6 kB)\n",
            "Requirement already satisfied: google-generativeai in /usr/local/lib/python3.11/dist-packages (0.8.4)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.0.37)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (3.11.11)\n",
            "Collecting langchain-core<0.4.0,>=0.3.33 (from langchain)\n",
            "  Downloading langchain_core-0.3.33-py3-none-any.whl.metadata (6.3 kB)\n",
            "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.5)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.17 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.2)\n",
            "Requirement already satisfied: numpy<2,>=1.22.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (1.26.4)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.10.6)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.32.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain) (9.0.0)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain-community)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting httpx-sse<0.5.0,>=0.4.0 (from langchain-community)\n",
            "  Downloading httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\n",
            "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain-community)\n",
            "  Downloading pydantic_settings-2.7.1-py3-none-any.whl.metadata (3.5 kB)\n",
            "Collecting filetype<2.0.0,>=1.2.0 (from langchain-google-genai)\n",
            "  Downloading filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: google-ai-generativelanguage==0.6.15 in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (0.6.15)\n",
            "Requirement already satisfied: google-api-core in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.19.2)\n",
            "Requirement already satisfied: google-api-python-client in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.155.0)\n",
            "Requirement already satisfied: google-auth>=2.15.0 in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.27.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (4.25.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (4.12.2)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from google-ai-generativelanguage==0.6.15->google-generativeai) (1.26.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.18.3)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core->google-generativeai) (1.66.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai) (5.5.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai) (4.9)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.33->langchain) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.33->langchain) (24.2)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (3.10.15)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (0.23.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.27.2)\n",
            "Collecting python-dotenv>=0.21.0 (from pydantic-settings<3.0.0,>=2.4.0->langchain-community)\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2024.12.14)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\n",
            "Requirement already satisfied: httplib2<1.dev0,>=0.19.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai) (0.22.0)\n",
            "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai) (0.2.0)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai) (4.1.1)\n",
            "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.70.0)\n",
            "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.62.3)\n",
            "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.11/dist-packages (from httplib2<1.dev0,>=0.19.0->google-api-python-client->google-generativeai) (3.2.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (3.7.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.33->langchain) (3.0.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai) (0.6.1)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.3.1)\n",
            "Downloading langchain-0.3.17-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m20.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_community-0.3.16-py3-none-any.whl (2.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m47.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_google_genai-2.0.9-py3-none-any.whl (41 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.7/41.7 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
            "Downloading httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n",
            "Downloading langchain_core-0.3.33-py3-none-any.whl (412 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m412.7/412.7 kB\u001b[0m \u001b[31m24.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydantic_settings-2.7.1-py3-none-any.whl (29 kB)\n",
            "Downloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: filetype, python-dotenv, mypy-extensions, marshmallow, httpx-sse, typing-inspect, pydantic-settings, dataclasses-json, langchain-core, langchain, langchain-google-genai, langchain-community\n",
            "  Attempting uninstall: langchain-core\n",
            "    Found existing installation: langchain-core 0.3.32\n",
            "    Uninstalling langchain-core-0.3.32:\n",
            "      Successfully uninstalled langchain-core-0.3.32\n",
            "  Attempting uninstall: langchain\n",
            "    Found existing installation: langchain 0.3.16\n",
            "    Uninstalling langchain-0.3.16:\n",
            "      Successfully uninstalled langchain-0.3.16\n",
            "Successfully installed dataclasses-json-0.6.7 filetype-1.2.0 httpx-sse-0.4.0 langchain-0.3.17 langchain-community-0.3.16 langchain-core-0.3.33 langchain-google-genai-2.0.9 marshmallow-3.26.1 mypy-extensions-1.0.0 pydantic-settings-2.7.1 python-dotenv-1.0.1 typing-inspect-0.9.0\n"
          ]
        }
      ],
      "source": [
        "pip install --upgrade langchain langchain-community langchain-google-genai google-generativeai\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "EW_9uVCLNmc8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import the required Libraries"
      ],
      "metadata": {
        "id": "0BliiHciOLTZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_google_genai import GoogleGenerativeAI\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.chains import LLMChain"
      ],
      "metadata": {
        "id": "g81X-jT5OQPP"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Configure the Gemini Flash Model"
      ],
      "metadata": {
        "id": "dswHy4pDOi7O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Configure the gemini flash model\n",
        "llm = GoogleGenerativeAI(\n",
        "    api_key = \"gemini_api_key\",\n",
        "    model =\"gemini-1.5-flash\",\n",
        "    temperature=0.7\n",
        "\n",
        ")"
      ],
      "metadata": {
        "id": "wY_7dPbAOrBQ"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create a prompt template"
      ],
      "metadata": {
        "id": "fxRBITXtPmWr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_template=PromptTemplate(\n",
        "    input_variables=[\"question\"],\n",
        "    template=\"\"\"You are a helpful assistant that provides clear,concise and well structured answers. Pleaseanswer te following questions in a structured way with bullet points if necessary.\n",
        "    Question :{question}\"\"\"\n",
        ")"
      ],
      "metadata": {
        "id": "W21qO3gxPosY"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Build the Langchain Pipeline"
      ],
      "metadata": {
        "id": "g9fMqO1cSeI5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.memory import ConversationBufferMemory\n",
        "memory = ConversationBufferMemory(input_key=\"question\",memory=\"history\")\n",
        "#Create the LLm Chain with memory\n",
        "chain = LLMChain(llm = llm ,prompt = prompt_template,memory = memory)\n",
        "\n"
      ],
      "metadata": {
        "id": "TmxZZa7PQjJ1"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Multi-turn conversation"
      ],
      "metadata": {
        "id": "RnBVYeNYS_Ea"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "question1 = \"What is LangChain?\"\n",
        "response1 = chain.invoke({\"question\": question1})\n",
        "print(\"Answer 1:\", response1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HbHRcsjDTB6q",
        "outputId": "f36d5895-513d-4512-f992-d0569cfd9c6f"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Answer 1: {'question': 'What is LangChain?', 'history': 'Human: What is Langchain?\\nAI: LangChain is a framework for developing applications powered by language models.  It simplifies the process of building applications that utilize LLMs by providing tools and components for:\\n\\n* **Connecting to various LLMs:** LangChain allows you to easily switch between different language models (like OpenAI, Hugging Face Hub models, etc.) without modifying your core application logic.\\n\\n* **Managing memory:**  It offers mechanisms for LLMs to remember previous interactions within a conversation, improving context and coherence.  This includes various memory types, allowing you to tailor memory management to your specific application needs.\\n\\n* **Chain building:** This is a core feature, enabling the creation of complex workflows involving multiple LLMs or other components (e.g.,  databases, APIs).  Chains allow you to combine different LLMs and tools to achieve more sophisticated tasks.\\n\\n* **Agents:** LangChain provides tools to build agents that can decide which tools or LLMs to use based on the user\\'s request.  This allows for more autonomous and adaptable applications.\\n\\n* **Indexes:**  These help you structure your own data to be effectively used with LLMs.  This is crucial for applications that need to interact with specific documents or datasets.\\n\\n\\nIn essence, LangChain acts as a powerful toolbox for developers, making it significantly easier to build robust and sophisticated applications leveraging the capabilities of large language models.  It abstracts away much of the complexity involved in integrating and managing LLMs, allowing developers to focus on the application logic.\\n\\nHuman:  How does it help with AI applications?\\nAI: That\\'s too broad a question.  To answer how something \"helps with AI applications,\" I need to know *what* that something is.  Please specify what you\\'re referring to.  For example:\\n\\n* \"How does **GPU acceleration** help with AI applications?\"\\n* \"How does **transfer learning** help with AI applications?\"\\n* \"How does **a large dataset** help with AI applications?\"\\n\\nOnce you provide the specific thing you\\'re asking about, I can give you a detailed and helpful answer.\\n\\nHuman: What is Langchain?\\nAI: LangChain is a framework for developing applications powered by language models.  It\\'s designed to make it easier to build applications that use LLMs effectively by providing modular components and helpful abstractions.  These components handle tasks like:\\n\\n* **Connecting to various LLMs:**  LangChain allows you to easily swap between different language models (like OpenAI\\'s GPT, Hugging Face models, etc.) without changing much of your code.\\n* **Managing memory:**  It offers mechanisms to allow LLMs to \"remember\" past interactions within a conversation, improving context and coherence.\\n* **Chains and agents:**  These are powerful features that allow you to orchestrate multiple calls to LLMs and other utilities (like search engines or databases) to accomplish complex tasks. Chains sequence calls, while agents decide which calls to make based on the current situation.\\n* **Prompts:**  LangChain provides tools to help you design and manage prompts effectively, crucial for getting good results from LLMs.\\n* **Indexes:**  It helps you index and query your own data to use with LLMs, allowing you to build applications that access and process your private information.\\n\\nIn short, LangChain simplifies the process of building applications that leverage the power of large language models, moving beyond simple single-prompt interactions to create more sophisticated and useful applications.\\n\\nHuman: What is Langchain?\\nAI: LangChain is a framework for developing applications powered by language models.  It simplifies the process of building applications that use LLMs by providing tools and components for:\\n\\n* **Connecting to different LLMs:** LangChain allows you to easily switch between various language models (like OpenAI\\'s GPT, Hugging Face models, etc.) without rewriting significant portions of your code.\\n\\n* **Managing chains of calls:** It enables you to create complex workflows involving multiple language model calls, where the output of one call serves as input to the next. This is crucial for tasks requiring multiple steps, such as summarization followed by question answering.\\n\\n* **Memory management:**  LangChain offers mechanisms to maintain conversation history and context across multiple interactions with the LLM, leading to more coherent and relevant responses.  This is particularly important for chatbots and conversational agents.\\n\\n* **Data connection:**  It allows you to connect LLMs to your own data, enabling them to answer questions based on your specific documents or databases. This is done through components like document loaders and vector databases.\\n\\n* **Agent development:**  LangChain facilitates the creation of agents that can interact with their environment (e.g., querying a search engine or accessing a database) to gather information and complete tasks.\\n\\nIn essence, LangChain acts as a powerful toolkit for streamlining the development of LLM-powered applications, making it easier to build more sophisticated and versatile applications.  It abstracts away much of the underlying complexity, allowing developers to focus on the application logic rather than the intricate details of interacting with specific LLMs.\\n', 'text': \"LangChain is a framework for developing applications powered by large language models (LLMs).  It simplifies the process of building applications by providing tools and components for:\\n\\n* **Connecting to LLMs:**  It allows you to easily switch between different LLMs (like OpenAI's GPT models, Hugging Face models, etc.) without rewriting significant portions of your code.\\n\\n* **Managing Memory:**  LLMs are stateless, meaning they don't remember past interactions. LangChain provides memory mechanisms to allow your application to maintain context across multiple interactions with the LLM.  This is crucial for building conversational applications or applications that need to process sequences of information.\\n\\n* **Working with External Data:** LangChain enables you to connect LLMs to external data sources (databases, APIs, files) so the LLM can access and process information beyond its training data. This allows for more grounded and accurate responses.\\n\\n* **Chain Building:**  LangChain provides a way to chain together multiple LLMs and other components (like prompts, data processing functions) to create complex workflows. This allows you to build sophisticated applications with multiple steps.\\n\\n* **Agents:**  These allow your application to decide which tools (LLMs, external data sources) to use based on the user's input, enabling more autonomous and resourceful applications.\\n\\nIn essence, LangChain acts as a Lego-like system for building LLM-powered applications, providing pre-built blocks and connectors to accelerate development and make it easier to manage the complexity of working with LLMs.  It abstracts away much of the boilerplate code, allowing developers to focus on the application logic rather than the intricacies of LLM interaction.\\n\"}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Run the Hello World Example\n",
        "question2 = \"How does it help with AI applications?\"\n",
        "response2 = chain.invoke({\"question\": question2})  # ✅ Model remembers previous input\n",
        "print(\"Answer 2:\", response2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CqCTxdSyYifZ",
        "outputId": "915beee4-9ee4-4c6c-9847-b502002e9d74"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Answer 2: {'question': 'How does it help with AI applications?', 'history': '', 'text': 'That\\'s a very broad question!  To answer \"How does it help with AI applications?\", I need to know **what \"it\" refers to.**  \"It\" could be anything from a specific technology (like a new type of processor, a particular dataset, or a novel algorithm) to a more abstract concept (like increased computing power or a new ethical framework).\\n\\nPlease specify what \"it\" is referring to so I can provide a helpful and accurate answer.\\n'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "question3 = \"Can you summarize our discussion?\"\n",
        "response3 = chain.invoke({\"question\": question3})\n",
        "print(\"Answer 3:\", response3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "njB0s6OkZjKL",
        "outputId": "348817c0-26ea-46c9-fb29-90784e62a5db"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Answer 3: {'question': 'Can you summarize our discussion?', 'history': 'Human: How does it help with AI applications?\\nAI: That\\'s a very broad question!  To answer \"How does it help with AI applications?\", I need to know **what \"it\" refers to.**  \"It\" could be anything from a specific technology (like a new type of processor, a particular dataset, or a novel algorithm) to a more abstract concept (like increased computing power or a new ethical framework).\\n\\nPlease specify what \"it\" is referring to so I can provide a helpful and accurate answer.\\n', 'text': \"Please provide me with the discussion you'd like me to summarize. I need the content of our conversation to be able to summarize it for you.\\n\"}\n"
          ]
        }
      ]
    }
  ]
}